{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Create New Folders with 20 class instead of 500 class","metadata":{}},{"cell_type":"code","source":"# # run this script after extracting the dataset into a folder called \"archive\"\n# # it creates new folders with only a few classes\n\n# import os\n# import shutil\n# import random\n# from tqdm import tqdm\n# import json\n\n\n# def merge_folders(source_root,source_dir_list, target_dir):\n\n#     \"\"\"\n#     Merge two folders into one\n#     \"\"\"\n#     if not os.path.exists(target_dir):\n#         os.mkdir(target_dir)\n#     for source_dir in source_dir_list:\n#         full_path_source = os.path.join(source_root, source_dir)\n#         for root, dirs, files in os.walk(full_path_source):\n#             for file in files:\n#                 shutil.copy(os.path.join(root, file), os.path.join(target_dir, file))\n\n\n# def merge_folders_from_dict(source_path, destination_path):\n#     \"\"\"\"\"\"\n\n#     if not os.path.exists(destination_path):\n#         os.mkdir(destination_path)\n\n#     categories ={}\n#     with open('final_classes.json', 'r') as dict_reader:\n#         categories=json.load(dict_reader)\n\n#     for k, v in categories.items():\n#         target_dir = os.path.join(destination_path, k) \n#         #print(f'the target directory is: {target_dir}') \n#         merge_folders(source_path,v, target_dir)\n\n# merge_folders_from_dict('./archive/vinted_train', './archive/vinted_train_merged_folder')\n# merge_folders_from_dict('./archive/vinted_val', './archive/vinted_val_merged_folder')\n# shutil.rmtree('./archive/vinted_train')\n# shutil.rmtree('./archive/vinted_val')\n# os.rename('./archive/vinted_train_merged_folder', './archive/vinted_train')\n# os.rename('./archive/vinted_val_merged_folder', './archive/vinted_val')","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:06:30.501626Z","iopub.execute_input":"2022-05-06T12:06:30.502009Z","iopub.status.idle":"2022-05-06T12:06:30.529075Z","shell.execute_reply.started":"2022-05-06T12:06:30.501921Z","shell.execute_reply":"2022-05-06T12:06:30.528037Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# import os\n# import shutil\n# import random\n# from tqdm import tqdm\n\n# def make_train_val(folder, divider: int):\n#     train_folder, val_folder = f\"{folder}_train\", f\"{folder}_test_only\"\n#     # for every sub folder in folder\n#     for label in tqdm(os.listdir(folder), desc=\"Making train and test sets\"):\n#         # if label is not a folder\n#         if not os.path.isdir(os.path.join(folder, label)):\n#             continue\n#         # make train and val sub folders\n#         os.makedirs(os.path.join(train_folder, label), exist_ok=True)\n#         os.makedirs(os.path.join(val_folder, label), exist_ok=True)\n#         # for every file in sub folder\n#         filenames = os.listdir(os.path.join(folder, label))\n#         random.shuffle(filenames)\n#         modulo = min(len(filenames), divider) # val is 1/5th but should contain at least 1 element\n#         for i in range(len(filenames)):\n#             if i % modulo == 0:\n#                 shutil.copy(os.path.join(folder, label, filenames[i]), os.path.join(val_folder, label, filenames[i]))\n#             else:\n#                 shutil.copy(os.path.join(folder, label, filenames[i]), os.path.join(train_folder, label, filenames[i]))\n\n# os.rename(\"./archive/vinted_train\", \"./archive/vinted\")\n# make_train_val(folder=\"archive/vinted\", divider=5)\n# shutil.rmtree(\"./archive/vinted\")","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:06:30.531295Z","iopub.execute_input":"2022-05-06T12:06:30.532208Z","iopub.status.idle":"2022-05-06T12:06:30.538559Z","shell.execute_reply.started":"2022-05-06T12:06:30.532162Z","shell.execute_reply":"2022-05-06T12:06:30.537386Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# # then run this script to remove all classes with not enough images\n# # for example, if you have less than X images in the folder vinted_train you can remove it\n\n# min_nr_images = 100\n\n# for folder in [\"./archive/vinted_train\"]:\n#     for label in tqdm(os.listdir(folder), desc=f\"Removing classes with less than {min_nr_images} images\"):\n#         if not os.path.isdir(os.path.join(folder, label)):\n#             continue\n#         if len(os.listdir(os.path.join(folder, label))) < min_nr_images:\n#             shutil.rmtree(os.path.join(folder, label))\n#             if os.path.isdir(os.path.join(\"./archive/vinted_val\", label)):\n#                 shutil.rmtree(os.path.join(\"./archive/vinted_val\", label))\n#             if os.path.isdir(os.path.join(\"./archive/vinted_test_only\", label)):\n#                 shutil.rmtree(os.path.join(\"./archive/vinted_test_only\", label))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:06:30.540372Z","iopub.execute_input":"2022-05-06T12:06:30.541106Z","iopub.status.idle":"2022-05-06T12:06:30.553809Z","shell.execute_reply.started":"2022-05-06T12:06:30.541063Z","shell.execute_reply":"2022-05-06T12:06:30.552786Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom keras.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:06:30.555578Z","iopub.execute_input":"2022-05-06T12:06:30.557400Z","iopub.status.idle":"2022-05-06T12:06:36.701424Z","shell.execute_reply.started":"2022-05-06T12:06:30.557355Z","shell.execute_reply":"2022-05-06T12:06:36.700455Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Using Tensorflow","metadata":{}},{"cell_type":"code","source":"img_height = 100\nimg_width = 100\nbatch_size = 1024","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:06:36.702787Z","iopub.execute_input":"2022-05-06T12:06:36.703776Z","iopub.status.idle":"2022-05-06T12:06:36.713984Z","shell.execute_reply.started":"2022-05-06T12:06:36.703741Z","shell.execute_reply":"2022-05-06T12:06:36.712760Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.keras.utils.image_dataset_from_directory(\n  \"/kaggle/input/archive-vinted/archive/vinted_train\",\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width), batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:06:36.717104Z","iopub.execute_input":"2022-05-06T12:06:36.717976Z","iopub.status.idle":"2022-05-06T12:07:17.773265Z","shell.execute_reply.started":"2022-05-06T12:06:36.717924Z","shell.execute_reply":"2022-05-06T12:07:17.772317Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"val_ds = tf.keras.utils.image_dataset_from_directory(\n  \"/kaggle/input/archive-vinted/archive/vinted_val\",\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width), batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:07:17.775038Z","iopub.execute_input":"2022-05-06T12:07:17.775398Z","iopub.status.idle":"2022-05-06T12:07:24.333032Z","shell.execute_reply.started":"2022-05-06T12:07:17.775337Z","shell.execute_reply":"2022-05-06T12:07:24.332057Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class_names = train_ds.class_names\n#print(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:07:24.334797Z","iopub.execute_input":"2022-05-06T12:07:24.335280Z","iopub.status.idle":"2022-05-06T12:07:24.340082Z","shell.execute_reply.started":"2022-05-06T12:07:24.335216Z","shell.execute_reply":"2022-05-06T12:07:24.339067Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ntf.data.AUTOTUNE automatically tunes the mapping function to \nincrease parallel processing efficiency.\nNext, we shuffle only the train dataset with a buffer size of 1000\n\"\"\"\n    \nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:07:24.341716Z","iopub.execute_input":"2022-05-06T12:07:24.342257Z","iopub.status.idle":"2022-05-06T12:07:24.356523Z","shell.execute_reply.started":"2022-05-06T12:07:24.342211Z","shell.execute_reply":"2022-05-06T12:07:24.355573Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"normalization_layer = layers.Rescaling(1./255)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:07:24.358116Z","iopub.execute_input":"2022-05-06T12:07:24.358913Z","iopub.status.idle":"2022-05-06T12:07:24.383484Z","shell.execute_reply.started":"2022-05-06T12:07:24.358850Z","shell.execute_reply":"2022-05-06T12:07:24.382519Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))\nfirst_image = image_batch[0]\n# Notice the pixel values are now in `[0,1]`.\nprint(np.min(first_image), np.max(first_image))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:07:24.387591Z","iopub.execute_input":"2022-05-06T12:07:24.387856Z","iopub.status.idle":"2022-05-06T12:08:57.097178Z","shell.execute_reply.started":"2022-05-06T12:07:24.387826Z","shell.execute_reply":"2022-05-06T12:08:57.095996Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"num_classes = len(class_names)\n\nmodel = Sequential([\n  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n    ]) ","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:08:57.099025Z","iopub.execute_input":"2022-05-06T12:08:57.099397Z","iopub.status.idle":"2022-05-06T12:08:57.201611Z","shell.execute_reply.started":"2022-05-06T12:08:57.099354Z","shell.execute_reply":"2022-05-06T12:08:57.200506Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:08:57.203239Z","iopub.execute_input":"2022-05-06T12:08:57.203568Z","iopub.status.idle":"2022-05-06T12:08:57.221347Z","shell.execute_reply.started":"2022-05-06T12:08:57.203526Z","shell.execute_reply":"2022-05-06T12:08:57.220303Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:08:57.223382Z","iopub.execute_input":"2022-05-06T12:08:57.223819Z","iopub.status.idle":"2022-05-06T12:08:57.240519Z","shell.execute_reply.started":"2022-05-06T12:08:57.223773Z","shell.execute_reply":"2022-05-06T12:08:57.239580Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = \"train_vinted_file_1/cp.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Create a callback that saves the model's weights\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)\n\n# Train the model with the new callback\nepochs=20\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n  callbacks=[cp_callback]\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:08:57.242213Z","iopub.execute_input":"2022-05-06T12:08:57.242549Z","iopub.status.idle":"2022-05-06T12:12:04.370982Z","shell.execute_reply.started":"2022-05-06T12:08:57.242506Z","shell.execute_reply":"2022-05-06T12:12:04.369972Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\nplt.savefig('before_reduce_overfitting.png')","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:12:04.372933Z","iopub.execute_input":"2022-05-06T12:12:04.373637Z","iopub.status.idle":"2022-05-06T12:12:04.788773Z","shell.execute_reply.started":"2022-05-06T12:12:04.373576Z","shell.execute_reply":"2022-05-06T12:12:04.787789Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data_augmentation = keras.Sequential(\n  [\n    layers.RandomFlip(\"horizontal\",\n                      input_shape=(img_height,\n                                  img_width,\n                                  3)),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n  ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:12:04.790757Z","iopub.execute_input":"2022-05-06T12:12:04.791068Z","iopub.status.idle":"2022-05-06T12:12:04.951511Z","shell.execute_reply.started":"2022-05-06T12:12:04.791026Z","shell.execute_reply":"2022-05-06T12:12:04.950485Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#add layers.dropout\nmodel = Sequential([\n  data_augmentation,\n  layers.Rescaling(1./255),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.2),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:12:04.953017Z","iopub.execute_input":"2022-05-06T12:12:04.955335Z","iopub.status.idle":"2022-05-06T12:12:05.184480Z","shell.execute_reply.started":"2022-05-06T12:12:04.955240Z","shell.execute_reply":"2022-05-06T12:12:05.183430Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:12:05.186323Z","iopub.execute_input":"2022-05-06T12:12:05.186627Z","iopub.status.idle":"2022-05-06T12:12:05.202348Z","shell.execute_reply.started":"2022-05-06T12:12:05.186573Z","shell.execute_reply":"2022-05-06T12:12:05.201140Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\nplt.savefig('after_reduce_overfitting.png')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:12:05.204070Z","iopub.execute_input":"2022-05-06T12:12:05.204540Z","iopub.status.idle":"2022-05-06T12:12:05.577992Z","shell.execute_reply.started":"2022-05-06T12:12:05.204493Z","shell.execute_reply":"2022-05-06T12:12:05.577025Z"},"trusted":true},"execution_count":20,"outputs":[]}]}